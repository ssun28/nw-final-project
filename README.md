# nw-final-project

### Scan a particular website and extract useful information

Description for some features:

* robots.txt
* IP Address
* Whois detail
* weak issues
* location & phone call
or other info

So for the user, when he types a website, the bunches of info will come out

#### robots.txt

Web Robots (also known as Web Wanderers, Crawlers, or Spiders), are programs that traverse the Web automatically. Search engines such as Google use them to index the web content, spammers use them to scan for email addresses, and they have many other uses.

![robots.txt](https://bloggingwizard.com/wp-content/uploads/2017/03/Facebook-Robot.txt-File-Creating-An-Effective-Robots.txt-File-For-Your-Blog.png?w=651&ssl=1 ) 

#### Resources:

  * [http://www.robotstxt.org](http://www.robotstxt.org)
  * [https://support.google.com/webmasters/answer/6062608?hl=en](https://support.google.com/webmasters/answer/6062608?hl=en)
  * [https://www.youtube.com/watch?v=8ZZSd0cdymo](https://www.youtube.com/watch?v=8ZZSd0cdymo)
  
  
